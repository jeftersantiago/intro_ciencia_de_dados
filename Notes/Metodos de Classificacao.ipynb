{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZudljEANLSurltMTZaxwd6KQMLRyGKet","authorship_tag":"ABX9TyOuSMlUNqyFQSog/mkH7+0X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import random\n","import matplotlib.pyplot as plt \n","from matplotlib.pyplot import cm\n","import numpy as np\n","import pandas as pd\n","from pandas import DataFrame\n","from scipy.stats import multivariate_normal\n","from sklearn.neighbors import KernelDensity\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn import metrics\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.preprocessing import StandardScaler\n","from mlxtend.plotting import plot_decision_regions\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","from sklearn.neighbors import KNeighborsClassifier\n","import sklearn.datasets as skdata\n","from scipy.spatial import distance\n","import statistics"],"metadata":{"id":"TMQTN0w8-MPh","executionInfo":{"status":"ok","timestamp":1671396566463,"user_tz":180,"elapsed":1452,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Teoria da decisão Bayesiana\n","\n","+ $P(C_1|x)$ - Probabilidade de atributos x pertencer à classe $C_1$.\n","+ $P(C_2|x)$ - Probabilidade de atributos x pertencer à classe $C_2$.\n","\n","Se $P(C_1|x) > P(C_2|x)$ então classifique $x \\in C_1$, o mesmo vale\n","para o caso inverso.\n","\n","Pelo teorema de Bayes temos \n","$$ P(C_j| x) = \\frac{P(x|C_j)P(C_j)}{p(x)}, j \\in \\mathbb{N}^*$$\n","onde $P(x|C_j)$ é uma função de densidade de probabilidade e $P(C_j)$ é uma distribuição de variaveis aleatórias discretas.\n","Assumimos $P(C_j|) \\sim p(x | C_j)$\n"],"metadata":{"id":"gO1xmwKgo7Wd"}},{"cell_type":"markdown","source":["## Probabilidade de erro na classificação\n","\n","$$p_e = p(X \\in R_1, C_2) + p(X \\in R_2, C_1) = p(X \\in R_1|C_2)P(C_2) + p(X \\in R_2| C_1)P(C_1)$$\n","$$p_e = \\int_{R_1} p(X|C_2)P(C_2)dx + \\int_{R_2}p(X|C_1)P(C_1)dx$$\n","\n","mas $P(C_j|x) = \\frac{p(X|C_j)P(C_j)}{p(X)} \\longrightarrow P(C_j|X)p(X)$\n","\n","$$p_e = \\int_{R_1} p(C_2|X)p(X)dx + \\int_{R_2} P(C_1|X)p(X) dx$$\n","\n","$$ P(C_1) = \\int_{-\\infty}^{\\infty} P(x_i c_i) dx = \\int_{-\\infty}^{\\infty}P(C_1|X)p(X)dx = \\int_{R_1}P(C_1|X)p(X)dx + \\int_{R_2}P(C_1|X)p(X)dx$$\n","\n","Substituindo em $p_e$: \n","\n","$$ p_e = \\int_{R_1} P(C_2|X)p(X) dx + P(C_1) - \\int_{R_1}P(C_1|X)p(X)dx$$\n","\n","$$ p_e = P(C_1) - \\int_{R_1} \\left[ P(C_1|X) - P(C_2|X)\\right] p(X) dx $$\n","\n","\n"],"metadata":{"id":"eANlJj6_qyh4"}},{"cell_type":"markdown","source":["O erro será mínimo se: $ P(C_1|X) - P(C_2|X) > 0 $ em $R_1$. "],"metadata":{"id":"z3ZE8Wbjwpat"}},{"cell_type":"markdown","source":["## Classificação Bayesiana: estimação paramétrica\n","\n","\n","Sejam $X_1, X_2, \\cdots, X_n$ uma amostra aleatória da população, assumindo independência dos elementos da amostra \n","$$p(X; \\theta) = p(x_1, x_2, \\cdots,x_n) = \\prod_{i = 1}^{n} p(x_i; \\theta) $$\n","o estimador de máxima verossimilhança é dado por \n","$$\\hat{\\theta} = \\text{argmax}_{\\theta}\\prod_{i = 1}^{n} p(x_i; \\theta)$$\n","ou\n","$$ L(\\theta) = \\log p(X; \\theta) = \\sum_{i = 1}^{n} \\log p(X; \\theta) $$\n","\n","\n","Estimadores de verossimilhanã são assintoticamente não-viesados, ou seja, a média, para um número de amostras muito grande converge para um número real: $\\lim_{n \\to \\infty} E[\\hat{\\theta}] = \\theta_0$.\n","  "],"metadata":{"id":"z_ia3AxdwBuC"}},{"cell_type":"markdown","source":["## Classificação não-paramétrica\n","Considerando para uma função de 1 variável, temos que \n","$$ \\hat{f}_{h} (x) = \\frac{1}{n} \\sum_{i = 1}^{n} K_h (x - x_i) = \\frac{1}{nh} \\sum_{i = 1}^{n} K \\left( \\frac{x - x_i}{h} \\right)$$\n"," onde $K$ é uma função kernel calculada em cada ponto e $h$ é chamado de hiperparametro.\n"],"metadata":{"id":"aUgGElzb0YSu"}},{"cell_type":"markdown","source":["# Implementação do classificador Bayesiano"],"metadata":{"id":"NZ04hUQHGdLP"}},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Introdução à Ciência de Dados/data/Vehicle.csv')\n","data = data.dropna(axis = 'rows')\n","\n","classes = np.array(pd.unique(data[data.columns[-1]]),  dtype = str)\n","\n","data = data.to_numpy()\n","nrow, ncol = data.shape\n","\n","y = data[:, -1]\n","X = data[:, 0:ncol - 1]"],"metadata":{"id":"PBCcjiKRGkmE","executionInfo":{"status":"ok","timestamp":1671396567196,"user_tz":180,"elapsed":735,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["scaler = StandardScaler().fit(X)\n","X = scaler.transform(X)"],"metadata":{"id":"Vwnes_CIHpvn","executionInfo":{"status":"ok","timestamp":1671396567197,"user_tz":180,"elapsed":6,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["p = 0.6\n","x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 302)"],"metadata":{"id":"IMthhmepHkgs","executionInfo":{"status":"ok","timestamp":1671396567197,"user_tz":180,"elapsed":5,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Caso paramétrico\n","Assumindo que cada variável está distribuida a partir de uma distribuição Normal."],"metadata":{"id":"RyrpM-UHH1i_"}},{"cell_type":"code","source":["P = pd.DataFrame(data=np.zeros((x_test.shape[0], len(classes))), columns = classes) \n","\n","Pc = np.zeros(len(classes))\n","for i in np.arange(0, len(classes)):\n","    elements = tuple(np.where(y_train == classes[i]))\n","    Pc[i] = len(elements)/len(y_train)\n","    Z = x_train[elements,:][0]\n","    m = np.mean(Z, axis = 0)\n","    cv = np.cov(np.transpose(Z))\n","    for j in np.arange(0,x_test.shape[0]):\n","        x = x_test[j,:]\n","        pj = multivariate_normal.pdf(x, mean=m, cov=cv, allow_singular=True)\n","        P[classes[i]][j] = pj*Pc[i]\n"],"metadata":{"id":"Qkmde2GNIDYk","executionInfo":{"status":"ok","timestamp":1671396567615,"user_tz":180,"elapsed":422,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["y_pred = []\n","#np.array(test_x.shape[0], dtype=str)\n","for i in np.arange(0, x_test.shape[0]):\n","    c = np.argmax(np.array(P.iloc[[i]]))\n","    y_pred.append(classes[c])\n","y_pred = np.array(y_pred, dtype=str)\n","# print(y_pred)"],"metadata":{"id":"NQ2F73cnIOve","executionInfo":{"status":"ok","timestamp":1671396568087,"user_tz":180,"elapsed":475,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["score = accuracy_score(y_pred, y_test)\n","print('Accuracy:', score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2Z-fFLCITGz","executionInfo":{"status":"ok","timestamp":1671396568088,"user_tz":180,"elapsed":69,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}},"outputId":"581323d1-5f62-41ba-9315-2ce773e8955e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8584070796460177\n"]}]},{"cell_type":"markdown","source":["## Caso não paramétrico\n","Para o caso unidimensional seja uma amostra identicamente distribuida de acordo com uma função $f$ não conhecida. Usamos um estimador (Kernel density estimator):\n","$$ \\hat{f}_{h} (x) = \\frac{1}{n} \\sum_{i = 1}^{n} K_h (x - x_i) = \\frac{1}{nh} \\sum_{i = 1}^{n} K \\left( \\frac{x - x_i}{h} \\right)$$\n","nesse caso a estimação depende do parâmetro $h$, que controla a abertura da função.\n","\n"],"metadata":{"id":"yvRng0LCIX15"}},{"cell_type":"code","source":["p = 0.8 # fraction of elements in the test set\n","x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)"],"metadata":{"id":"7w3CgSyeIZ8Q","executionInfo":{"status":"ok","timestamp":1671396568088,"user_tz":180,"elapsed":13,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["p = pd.DataFrame(data=np.zeros((x_train.shape[0], len(classes))), columns = classes)\n","pc = np.zeros(len(classes))\n","  \n","h = 0.6\n","\n","for i in np.arange(0, len(classes)):\n","    elements = tuple(np.where(y_train == classes[i]))\n","    pc[i] = len(elements) / len(y_train)\n","    z = x_train[elements, :][0]\n","    kde = KernelDensity(kernel = 'gaussian', bandwidth=h).fit(z)\n","    for j in np.arange(0, x_test.shape[0]):\n","      x = x_test[j, :]\n","      x = x.reshape((1, len(x)))\n","      pj = np.exp(kde.score_samples(x))\n","      p[classes[i]][j] = pj * pc[i]\n","y_pred = []\n","\n","for i in np.arange(0, x_test.shape[0]):\n","  c = np.argmax(np.array(p.iloc[[i]]))\n","  y_pred.append(classes[c])\n","  \n","y_pred = np.array(y_pred, dtype = str)\n","\n","score = accuracy_score(y_pred, y_test)\n","print(\"Acuracia: \", score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8fFAv-LK8rV","executionInfo":{"status":"ok","timestamp":1671396568089,"user_tz":180,"elapsed":13,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}},"outputId":"d882f676-eeed-4807-dd41-be8c1c0899bc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Acuracia:  0.7176470588235294\n"]}]},{"cell_type":"code","source":["v_accuracy = []\n","v_h = np.linspace(0.1, 5, 100)\n","\n","for h in v_h:\n","  p = pd.DataFrame(data=np.zeros((x_train.shape[0], len(classes))), columns = classes)\n","\n","  pc = np.zeros(len(classes))\n","\n","  for i in np.arange(0, len(classes)):\n","    elements = tuple(np.where(y_train == classes[i]))\n","    pc[i] = len(elements) / len(y_pred)\n","\n","    z = x_train[elements, :][0]\n","    kde  = KernelDensity(kernel = 'gaussian', bandwidth = h).fit(z)\n","\n","    for j in np.arange(0, x_test.shape[0]):\n","      x = x_test[j, :]\n","      x = x.reshape((1, len(x)))\n","      pj = np.exp(kde.score_samples(x))\n","      p[classes[i]][j] = pj * pc[i]\n","  \n","  y_pred = []  \n","  for i in np.arange(0, x_test.shape[0]):\n","    c = np.argmax(np.array(p.iloc[[i]]))\n","    y_pred.append(classes[c])\n","\n","  y_pred = np.array(y_pred, dtype = int)\n","  score = accuracy_score(y_pred, y_test)\n","  v_accuracy.append(score)\n"],"metadata":{"id":"i-CmsaITMkQw","executionInfo":{"status":"error","timestamp":1671396568455,"user_tz":180,"elapsed":373,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}},"outputId":"69ecb7da-52be-445e-8cb8-941f7ea44ff4","colab":{"base_uri":"https://localhost:8080/","height":250}},"execution_count":10,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-04841d71995b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mv_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'bus'"]}]},{"cell_type":"code","source":["plt.figure(figsize=(10,4))\n","plt.plot(v_h, v_accuracy, 'o--', color = 'red', linewidth=1)\n","plt.xlabel('h', fontsize = 15)\n","plt.ylabel('Acurácia)', fontsize = 15)\n","plt.show()"],"metadata":{"id":"A1W7JMKFXLu1","executionInfo":{"status":"aborted","timestamp":1671396568458,"user_tz":180,"elapsed":26,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_h = v_h[np.argmax(v_accuracy)]\n","print(\"Melhor h: \", best_h)"],"metadata":{"id":"Qgu4eTuCX-xr","executionInfo":{"status":"aborted","timestamp":1671396568467,"user_tz":180,"elapsed":35,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Classificador Naive Bayes\n","\n","Não conhecemos a distribuição de probabilidade conjunta \n","$$ P(C_i| x) = \\frac{p(X|C_i) P(C_i)}{p(X)}  $$\n","então fazemos inferência assumindi primeiramente a independência entre os \n","atributos, ou seja \n","$$P(C_i|x) = \\frac{p(x|C_i)P(C_i)}{p(x)}$$ \n","$$ p(x|C_i) = \\prod_{j = 1}^{d} p(x_j|C_i), i = 1, 2, \\cdots, k $$\n","\n","e a classificação usa da regra de Bayes \n","$$ C_m = \\underbrace{\\text{argmax}}_{i \\in \\{1, \\cdots, M\\}} p(C_i) \\prod_{j = 1}^{d} p(x_j | C_i) $$\n","\n"],"metadata":{"id":"ovvVrsZ59Oir"}},{"cell_type":"markdown","source":["## Implementando o classificador Naive Bayes assumindo distribuição normal\n","Vamos assumir que a distribuição é do tipo normal, ou seja \n","$$ p(x_j | C_i) = \\frac{1}{\\sqrt{2\\pi \\sigma_{C_i}}} exp \\left[ - \\frac{1}{2} \\left( \\frac{x_j - \\mu_{C_i}}{\\sigma_{C_i}} \\right)^2 \\right]$$\n","\n","Assumindo a independência, o calculo de observação $q$ será \n","$$ p(x_q | C_i) = \\prod_{i = 1}^{d} p (x_{q, j} | C_i) , i = 1, 2, \\cdots, k$$\n","\n","a classificação de acordo com a classe mais provável será\n"," $$ \\hat{y} = \\text{arg} \\underbrace{\\text{max}}_{i = 1, \\cdots, k} P(C_i) \\prod_{j = 1}^{d} p(x_{q, j} | C_i)$$\n"],"metadata":{"id":"_RNy1M-jBn4j"}},{"cell_type":"markdown","source":["# Implementação do classificador Naive Bayes"],"metadata":{"id":"p_fw8V-CGV0X"}},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Introdução à Ciência de Dados/data/Vehicle.csv')\n","data = data.dropna(axis = 'rows')\n","\n","classes = np.array(pd.unique(data[data.columns[-1]]),  dtype = str)"],"metadata":{"id":"FN1ly_vA_WTs","executionInfo":{"status":"aborted","timestamp":1671396568468,"user_tz":180,"elapsed":36,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = data.to_numpy()\n","nrow, ncol = data.shape\n","\n","y = data[:, -1]\n","X = data[:, 0:ncol - 1]"],"metadata":{"id":"xSPcSIdv_0Ff","executionInfo":{"status":"aborted","timestamp":1671396568469,"user_tz":180,"elapsed":36,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p = 0.6\n","x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 302)"],"metadata":{"id":"D6vODuqCC3Aq","executionInfo":{"status":"aborted","timestamp":1671396568469,"user_tz":180,"elapsed":36,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Definindo uma função de verossimilhança"],"metadata":{"id":"xNw4wAGbDHkG"}},{"cell_type":"code","source":["def likelyhood(y, z):\n","  def gaussian(x, mu, sig):\n","    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n","  prob = 1\n","  for j in np.arange(0, z.shape[1]):\n","    m = np.mean(z[:, j])\n","    s = np.std(z[:, j])\n","    prob = prob * gaussian(y[j], m, s)\n","  return prob"],"metadata":{"id":"pjNZx9_J_6HQ","executionInfo":{"status":"aborted","timestamp":1671396568470,"user_tz":180,"elapsed":36,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p = pd.DataFrame(data = np.zeros((x_test.shape[0], len(classes))), columns = classes)\n","for i in np.arange(0, len(classes)):\n","  elements = tuple(np.where(y_train == classes[i]))\n","  z = x_train[elements, :][0]\n","  for j in np.arange(0, x_test.shape[0]):\n","    xj = x_test[j, :]\n","    pj = likelyhood(xj, z)\n","    p[classes[i]][j] = pj * len(elements) / x_train.shape[0]"],"metadata":{"id":"3AcGO7qLDfvF","executionInfo":{"status":"aborted","timestamp":1671396568471,"user_tz":180,"elapsed":37,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p.head(10)"],"metadata":{"id":"GE_rp03hEFdh","executionInfo":{"status":"aborted","timestamp":1671396568472,"user_tz":180,"elapsed":37,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = []\n","for i in np.arange(0, p.shape[0]):\n","    c = np.argmax(np.array(p.iloc[[i]]))\n","    y_pred.append(p.columns[c])\n","y_pred = np.array(y_pred, dtype=str)\n","\n","score = accuracy_score(y_pred, y_test)\n","print('Accuracy:', score)"],"metadata":{"id":"RHY8MbQ1EKHz","executionInfo":{"status":"aborted","timestamp":1671396568473,"user_tz":180,"elapsed":38,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Usando os métodos já implementados pelo scikit-learn"],"metadata":{"id":"Lp-3TaEmEa7b"}},{"cell_type":"code","source":["model = GaussianNB()\n","model.fit(x_train, y_train)\n","\n","y_pred = model.predict(x_test)\n","score = accuracy_score(y_pred, y_test)\n","print('Accuracy:', score)"],"metadata":{"id":"7iWoLW85Egum","executionInfo":{"status":"aborted","timestamp":1671396568474,"user_tz":180,"elapsed":38,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BernoulliNB()\n","\n","model.fit(x_train, y_train)\n","\n","y_pred = model.predict(x_test)\n","score = accuracy_score(y_pred, y_test)\n","print('Accuracy:', score)"],"metadata":{"id":"2cWwP08XEnB7","executionInfo":{"status":"aborted","timestamp":1671396568474,"user_tz":180,"elapsed":38,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gera os dados em duas dimensões\n","n_samples = 100 # número de observações\n","# centro dos grupos\n","centers = [(-4, 0), (0, 0), (3, 3)]\n","X, y = skdata.make_blobs(n_samples=100, n_features=2, cluster_std=1.0, centers=centers, \n","                         shuffle=False, random_state=42)\n","\n","# monta a matrix de atributos\n","d = np.column_stack((X,np.transpose(y)))\n","# converte para o formato dataframe do Pandas\n","data = DataFrame(data = d, columns=['X1', 'X2', 'y'])\n","features_names = ['X1', 'X2']\n","class_labels = np.unique(y)"],"metadata":{"id":"UM9k0V6QF6yJ","executionInfo":{"status":"aborted","timestamp":1671396568475,"user_tz":180,"elapsed":38,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["colors = ['red', 'blue', 'green', 'black']\n","aux = 0\n","for c in class_labels:\n","    ind = np.where(y == c)\n","    plt.scatter(X[ind,0][0], X[ind,1][0], color = colors[aux], label = c)\n","    aux = aux + 1\n","plt.legend()\n","plt.show()\n","\n","# Training a classifier\n","model = GaussianNB()\n","model.fit(X, y)\n","\n","# Plotting decision regions\n","plot_decision_regions(X, y, clf=model, legend=2)\n","\n","plt.xlabel('X1')\n","plt.ylabel('X2')\n","plt.title('Decision Regions')\n","plt.show()"],"metadata":{"id":"DqaIAbLWF2Lu","executionInfo":{"status":"aborted","timestamp":1671396568479,"user_tz":180,"elapsed":42,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# KNN\n","É criado um vetor de atributos para cada classe e então calculado as distâncias entre os atributos.\n","\n","## Definição da distância\n","\n","É comparada várias medidas de distância (euclidiana, manthattan ...)\n","\n","### Medidas de proximidade\n","- **Medida de similaridade**: $d(X_i, X_i)$ é máxima.\n","  + $s(p, q) = 1, p = q$;\n","  + $s(p, q) = s(q, p)$\n","- **Medida de dissimilaridade**: $d(X_i, X_i) = 0$.\n","  + $d(p, q) \\ge 0, ∀ p, q$ e $d(p, q) = 0$, se e só se $p = q$.\n","  + $d(p, q) = d(q, p)$.\n","  + $d(p, r) \\le d(p, q) + d(q, r), ∀ p, q, r$ onde $d(p,q)$ é a distância de dissimilaridade entre $p$ e $q$.\n","\n","## Métricas de distância \n","### **Dissimilaridade**\n","- Euclidiana \n","$$ D(X, Y) = \\sqrt{ \\sum_{i = 1}^{n} (x_i - y_i)^2}, x, y \\in [0, \\infty)$$\n","\n","- Minkowski \n","$$ D(X, Y) = \\left( \\sum_{i = 1}^{n} | x_i - y_i |^p\\right)^{\\frac{1}{p}}, x, y \\in [0, \\infty) $$\n","\n","### **Similaridade**\n","- Cosseno \n","$$ D(X, Y) = \\frac{\\sum_{i = 1}^{n} x_i y_i}{\\sqrt{\\sum_{i = 1}^{n} (x_i)^2}\\sqrt{\\sum_{i = 1}^{n} (y_i)^2}} x, y \\in [0, 1]$$ \n","\n","- Pearson \n","$$ D(X, Y) = \\frac{\\sum_{i = 1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i = 1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i = 1}^{n} (y_i - \\bar{y})^2}}, x, y \\in [-1, 1] $$"],"metadata":{"id":"Du0JWHiPYdy_"}},{"cell_type":"markdown","source":["## Algoritmo KNN\n","\n","+ Identifique os K vizinhos mais proximos do vetor de atributos $X$ que se quer classificar.\n","+ Determine o número de vizinhos em cada classe.\n","+ Classifique $X$ como pertencente à classe que resultou em maior número de vizinhos\n","\n","$$ p (y = j | X ) = \\frac{1}{k} \\sum_{i \\in R}\\{y_i = j\\} $$"],"metadata":{"id":"kpTST3itbv7H"}},{"cell_type":"markdown","source":["## Implementação do KNN"],"metadata":{"id":"46Uf0kI5imS1"}},{"cell_type":"code","source":["def knn(x_train, y_train, x_test, k):\n","    distances = [] \n","    x1 = x_test \n","    for x2 in x_train: \n","        dist = distance.euclidean(x1,x2)\n","        distances.append(dist)\n","    indices = []\n","    cl = []\n","    for i in range(0,k):\n","        ind = np.argmin(distances)\n","        #print('distance:', distances[ind],'index:', ind, 'class:', y_train[ind])\n","        distances[ind] = np.max(distances) \n","        indices.append(ind)\n","        cl.append(y_train[ind])\n","    print(\"Classes:\",cl)\n","    classification = statistics.mode(cl)\n","    return classification\n"],"metadata":{"id":"DwCLw7LOneYm","executionInfo":{"status":"aborted","timestamp":1671396568480,"user_tz":180,"elapsed":43,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k=3 # numero de vizinhos\n","x_train = np.array([[1,0.5],[0.8,0.8],[1.2,1.4],[0.6,0.4],[0.4,1.2],[1.5,1]])\n","y_train = np.array(['white','gray','white','gray','gray','white'], dtype = 'str')\n","x_test = np.array([1,1])\n","# realiza a classificacao\n","cl = knn(x_train, y_train, x_test, k)\n","print(\"Classification:\", cl)"],"metadata":{"id":"YvjQWRQinv4N","executionInfo":{"status":"aborted","timestamp":1671396568481,"user_tz":180,"elapsed":43,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.spatial import Voronoi, voronoi_plot_2d\n","from sklearn import datasets\n","from sklearn.neighbors import KNeighborsClassifier\n","import sklearn.datasets as skdata\n","from matplotlib import pyplot\n","\n","plt.scatter(x_train[:,0],x_train[:,1],c=y_train, s=150, marker='o', edgecolor='black')\n","plt.plot(x_test[0],x_test[1], marker='s', markersize=15, color=\"black\")\n","plt.xlim(0.2,1.6)\n","plt.ylim(0,1.6)\n","plt.savefig('knn.eps')\n","\n","plt.show()"],"metadata":{"id":"BJoKzzBOn0eD","executionInfo":{"status":"aborted","timestamp":1671396568482,"user_tz":180,"elapsed":44,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.spatial import Voronoi, voronoi_plot_2d\n","from sklearn import datasets\n","from sklearn.neighbors import KNeighborsClassifier\n","import sklearn.datasets as skdata\n","from matplotlib import pyplot"],"metadata":{"id":"uXXHxR5joBSq","executionInfo":{"status":"aborted","timestamp":1671396568482,"user_tz":180,"elapsed":44,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gera os dados em duas dimensões\n","n_samples = 100 # número de observações\n","# centro dos grupos\n","centers = [(0, 0), (-2, -2), (2,0)]\n","X, y = skdata.make_blobs(n_samples=100, n_features=2, cluster_std=1.0, centers=centers, \n","                         shuffle=False, random_state=42)\n","\n","# monta a matrix de atributos\n","d = np.column_stack((X,np.transpose(y)))\n","# converte para o formato dataframe do Pandas\n","data = DataFrame(data = d, columns=['X1', 'X2', 'y'])\n","features_names = ['X1', 'X2']\n","class_labels = np.unique(y)\n","\n","# mostra os dados e colori de acordo com as classes\n","colors = ['red', 'blue', 'green', 'black']\n","aux = 0\n","for c in class_labels:\n","    ind = np.where(y == c)\n","    plt.scatter(X[ind,0][0], X[ind,1][0], color = colors[aux], label = c)\n","    aux = aux + 1\n","plt.savefig('knn_ex.eps')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"O68LoYsfoC3R","executionInfo":{"status":"aborted","timestamp":1671396568483,"user_tz":180,"elapsed":45,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mostra as regiões de separação para diversos valores de k\n","vk = [1,5,10,20,int(n_samples/2)]\n","for k in vk:\n","    # Training a classifier\n","    model = KNeighborsClassifier(n_neighbors=k, metric = 'euclidean')\n","    model.fit(X, y)\n","    # Plotting decision regions\n","    plot_decision_regions(X, y, clf=model, legend=2)\n","    plt.xlabel('X1')\n","    plt.ylabel('X2')\n","    plt.title('Decision Regions: k = '+str(k))\n","    #plt.savefig('knn_' + str(k)+'.eps')\n","    plt.show()"],"metadata":{"id":"nf7_6gDsoJEb","executionInfo":{"status":"aborted","timestamp":1671396568484,"user_tz":180,"elapsed":46,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Escolha do melhor $k$"],"metadata":{"id":"J9mfLuu6oPp1"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_validate\n","\n","# Gera os dados em duas dimensões\n","n_samples = 100 # número de observações\n","# centro dos grupos\n","centers = [(0, 0), (-2, -2), (2,0)]\n","X, y = skdata.make_blobs(n_samples=100, n_features=2, cluster_std=1.0, centers=centers, \n","                         shuffle=False, random_state=42)\n","\n","# monta a matrix de atributos\n","d = np.column_stack((X,np.transpose(y)))\n","# converte para o formato dataframe do Pandas\n","data = DataFrame(data = d, columns=['X1', 'X2', 'y'])\n","features_names = ['X1', 'X2']\n","class_labels = np.unique(y)\n","\n","nkf = 5 #number of folds\n","vk = [] # armazena os valores de k\n","vscore = []\n","for k in range(1, 20):\n","    model = KNeighborsClassifier(n_neighbors=k, metric = 'euclidean')\n","    # realiza a validação cruzada\n","    cv = cross_validate(model, X, y, cv=nkf)\n","    #print('k:', k, 'accurace:', cv['test_score'].mean())\n","    vscore.append(cv['test_score'].mean()) \n","    vk.append(k)\n","\n","plt.figure(figsize=(6,4))\n","plt.plot(vk, vscore, '-bo')\n","plt.xlabel('k', fontsize = 15)\n","plt.ylabel('Acuracy', fontsize = 15)\n","plt.show(True)\n","best_k = np.argmax(vscore)+1\n","print('Melhor k:', best_k)"],"metadata":{"id":"H6uCFIEloSD1","executionInfo":{"status":"aborted","timestamp":1671396568488,"user_tz":180,"elapsed":49,"user":{"displayName":"Jefter Santiago Mares","userId":"06255646643923309703"}}},"execution_count":null,"outputs":[]}]}